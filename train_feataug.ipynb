{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms as v2\n",
    "from torchvision.datasets import ImageFolder\n",
    "import warnings\n",
    "\n",
    "from src.utils import *\n",
    "from src.modules import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove('FaceDataset/Train_cropped/Tung20/.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose(\n",
    "    [v2.RandomHorizontalFlip(),\n",
    "        v2.RandomRotation(15),\n",
    "        v2.RandomResizedCrop(160, scale=(0.8, 1.0)),\n",
    "        v2.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        v2.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "        v2.RandomGrayscale(p=0.1),\n",
    "        v2.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        v2.Resize((160, 160)),\n",
    "     v2.ToTensor(),\n",
    "     v2.Lambda(lambda x: x + torch.randn_like(x) * 0.05),\n",
    "     fixed_image_standardization]\n",
    ")\n",
    "\n",
    "dataset = ImageFolder(\"FaceDataset/Train_cropped\", transform=transforms)\n",
    "loader = DataLoader(dataset, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "facenet_model = InceptionResnetV1(pretrained=\"casia-webface\", classify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1792, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "feature_agg = NetworkFeatureAggregator(facenet_model, ['block8'], device = device, train_backbone=True)\n",
    "features = feature_agg(torch.rand(64, 3, 160, 160).to(device))\n",
    "print(features['block8'].shape)\n",
    "features = [features[layer] for layer in ['block8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_layer = AugmentationLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceNetClassifierWithAugFMap(nn.Module):\n",
    "    def __init__(self, num_classes, aug_layer = None):\n",
    "        super(FaceNetClassifierWithAugFMap, self).__init__()\n",
    "        self.extractor = feature_agg\n",
    "        self.aug_layer = None if aug_layer is None else aug_layer\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1792, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.extractor(x)['block8']  \n",
    "        if self.aug_layer is not None:\n",
    "            features = self.aug_layer(features)\n",
    "        # features = features.view(features.size(0), -1)\n",
    "        x = self.fc(features)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "facenet = FaceNetClassifierWithAugFMap(num_classes=20, aug_layer=AugmentationLayer()).to(device)\n",
    "\n",
    "epochs = 100\n",
    "facenet_params = list(facenet.extractor.parameters())\n",
    "classifier_params = list(facenet.fc.parameters())\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': facenet_params, 'lr': 1e-4},\n",
    "    {'params': classifier_params, 'lr': 1e-3}\n",
    "])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss improved to 3.082892.\n",
      "Accuracy improved to 0.047619.\n",
      "Epoch: 0 | Train Loss: 3.0829, Train Accuracy: 0.0476\n",
      "Loss improved to 2.889499.\n",
      "Accuracy improved to 0.238095.\n",
      "Epoch: 1 | Train Loss: 2.8895, Train Accuracy: 0.2381\n",
      "Loss improved to 2.745481.\n",
      "Accuracy improved to 0.619048.\n",
      "Epoch: 2 | Train Loss: 2.7455, Train Accuracy: 0.6190\n",
      "Loss improved to 2.652667.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 3 | Train Loss: 2.6527, Train Accuracy: 0.6190\n",
      "Loss improved to 2.504272.\n",
      "Accuracy improved to 0.714286.\n",
      "Epoch: 4 | Train Loss: 2.5043, Train Accuracy: 0.7143\n",
      "Loss improved to 2.360831.\n",
      "Accuracy improved to 0.857143.\n",
      "Epoch: 5 | Train Loss: 2.3608, Train Accuracy: 0.8571\n",
      "Loss improved to 2.294186.\n",
      "Accuracy improved to 0.904762.\n",
      "Epoch: 6 | Train Loss: 2.2942, Train Accuracy: 0.9048\n",
      "Loss improved to 2.028974.\n",
      "Accuracy improved to 1.000000.\n",
      "Epoch: 7 | Train Loss: 2.0290, Train Accuracy: 1.0000\n",
      "Loss improved to 2.001529.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 8 | Train Loss: 2.0015, Train Accuracy: 0.9524\n",
      "Loss improved to 1.862663.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 9 | Train Loss: 1.8627, Train Accuracy: 1.0000\n",
      "Loss improved to 1.806558.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 10 | Train Loss: 1.8066, Train Accuracy: 1.0000\n",
      "Loss improved to 1.638263.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 11 | Train Loss: 1.6383, Train Accuracy: 1.0000\n",
      "Loss improved to 1.632323.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 12 | Train Loss: 1.6323, Train Accuracy: 0.9524\n",
      "Loss improved to 1.539791.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 13 | Train Loss: 1.5398, Train Accuracy: 1.0000\n",
      "Loss improved to 1.432402.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 14 | Train Loss: 1.4324, Train Accuracy: 1.0000\n",
      "Loss improved to 1.420865.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 15 | Train Loss: 1.4209, Train Accuracy: 1.0000\n",
      "Loss improved to 1.209380.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 16 | Train Loss: 1.2094, Train Accuracy: 1.0000\n",
      "Loss did not improve. Counter: 2/5\n",
      "Accuracy did not improve. Counter: 3/5\n",
      "Epoch: 17 | Train Loss: 1.2527, Train Accuracy: 1.0000\n",
      "Loss improved to 1.154300.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 18 | Train Loss: 1.1543, Train Accuracy: 0.9524\n",
      "Loss improved to 0.948312.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 19 | Train Loss: 0.9483, Train Accuracy: 1.0000\n",
      "Loss did not improve. Counter: 2/5\n",
      "Accuracy did not improve. Counter: 3/5\n",
      "Epoch: 20 | Train Loss: 0.9848, Train Accuracy: 1.0000\n",
      "Loss improved to 0.932025.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 21 | Train Loss: 0.9320, Train Accuracy: 1.0000\n",
      "Loss improved to 0.842142.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 22 | Train Loss: 0.8421, Train Accuracy: 1.0000\n",
      "Loss did not improve. Counter: 2/5\n",
      "Accuracy did not improve. Counter: 3/5\n",
      "Epoch: 23 | Train Loss: 0.8607, Train Accuracy: 1.0000\n",
      "Loss improved to 0.700265.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 24 | Train Loss: 0.7003, Train Accuracy: 1.0000\n",
      "Loss did not improve. Counter: 2/5\n",
      "Accuracy did not improve. Counter: 3/5\n",
      "Epoch: 25 | Train Loss: 0.7438, Train Accuracy: 1.0000\n",
      "Loss improved to 0.610700.\n",
      "Accuracy did not improve. Counter: 1/5\n",
      "Epoch: 26 | Train Loss: 0.6107, Train Accuracy: 1.0000\n",
      "Loss did not improve. Counter: 2/5\n",
      "Accuracy did not improve. Counter: 3/5\n",
      "Epoch: 27 | Train Loss: 0.6411, Train Accuracy: 1.0000\n",
      "Loss did not improve. Counter: 4/5\n",
      "Accuracy did not improve. Counter: 5/5\n",
      "Early stopping triggered!\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "best_train_loss = float('inf')\n",
    "best_train_acc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    facenet.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in (loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = facenet(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * y.size(0) \n",
    "        _, predicted = torch.max(y_pred, 1) \n",
    "        correct += (predicted == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    train_loss /= total \n",
    "    train_acc = correct / total \n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    early_stopping(train_loss, train_acc)\n",
    "    if train_loss < best_train_loss:\n",
    "        best_val_loss = train_loss\n",
    "        best_val_acc = train_acc\n",
    "        torch.save({\n",
    "            'facenet_state_dict': facenet.state_dict(),\n",
    "        }, 'models/best_model.pth')\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    torch.save({\n",
    "        'facenet_state_dict': facenet.state_dict(),\n",
    "    }, 'models/last_model.pth')\n",
    "    torch.save({\n",
    "        \"losses\": train_losses,\n",
    "        \"accuracies\": train_accuracies,\n",
    "    }, 'models/train_metrics.pth')\n",
    "    print(f\"Epoch: {epoch} | Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = v2.Compose(\n",
    "    [v2.Resize((160, 160)),\n",
    "     v2.ToTensor(),\n",
    "     fixed_image_standardization]\n",
    ")\n",
    "\n",
    "test_dataset = ImageFolder(\"FaceDataset/Test_cropped\", transform=transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 79.11205073995772\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0.0\n",
    "test_loss = 0.0\n",
    "\n",
    "checkpoint = torch.load(r'models/best_model_812_1910.pth', map_location=device)\n",
    "facenet.load_state_dict(checkpoint['facenet_state_dict'])\n",
    "\n",
    "facenet.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad(): \n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = facenet(x)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        total += y.size(0)\n",
    "test_acc = correct / total\n",
    "print(f\"Test Acc: {test_acc*100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
